{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmMMtjcz65Iy32boh13t24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joongwha/DeepRL-Agents/blob/master/pancancer_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에서 실행할 완전한 코드\n",
        "# CT DICOM 데이터를 사용한 CNN 모델 구현\n",
        "\n",
        "# 1. 필요한 라이브러리 설치 및 import\n",
        "!pip install pydicom opencv-python scikit-image tensorflow\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pydicom\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage.filters import gaussian\n",
        "\n",
        "# 2. DICOM 처리 함수\n",
        "def process_dicom_file(file_path, target_size=(64, 64)):\n",
        "    \"\"\"실제 DICOM 파일을 처리하는 함수\"\"\"\n",
        "    try:\n",
        "        dicom_data = pydicom.dcmread(file_path)\n",
        "        image = dicom_data.pixel_array\n",
        "\n",
        "        # HU 윈도우 레벨링 (폐 영역용)\n",
        "        window_center, window_width = 40, 400\n",
        "        min_hu = window_center - window_width // 2\n",
        "        max_hu = window_center + window_width // 2\n",
        "\n",
        "        image = np.clip(image, min_hu, max_hu)\n",
        "        image = (image - min_hu) / (max_hu - min_hu)\n",
        "\n",
        "        # 전처리\n",
        "        image = cv2.resize(image, target_size)\n",
        "        image = gaussian(image, sigma=0.5)\n",
        "        image = exposure.equalize_adapthist(image)\n",
        "\n",
        "        return np.stack([image, image, image], axis=-1).astype(np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"DICOM 파일 처리 오류: {e}\")\n",
        "        return None\n",
        "\n",
        "# 3. 샘플 데이터 생성 (실제 DICOM 데이터가 없을 때)\n",
        "def create_ct_dataset(num_samples=600, img_size=(64, 64)):\n",
        "    X, y = [], []\n",
        "    class_names = ['Normal', 'Pneumonia', 'Tumor']\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        img = np.random.normal(0.1, 0.05, img_size)\n",
        "        class_idx = i % 3\n",
        "\n",
        "        cy, cx = img_size[0]//2, img_size[1]//2\n",
        "        y_grid, x_grid = np.ogrid[:img_size[0], :img_size[1]]\n",
        "\n",
        "        # 폐 영역 시뮬레이션\n",
        "        lung1 = ((x_grid - cx + 15)**2 + (y_grid - cy)**2) < 12**2\n",
        "        lung2 = ((x_grid - cx - 15)**2 + (y_grid - cy)**2) < 12**2\n",
        "        img[lung1 | lung2] += 0.2\n",
        "\n",
        "        # 클래스별 특징 추가\n",
        "        if class_idx == 1:  # Pneumonia\n",
        "            mask = np.random.random(img_size) > 0.85\n",
        "            img[mask & (lung1 | lung2)] += 0.4\n",
        "        elif class_idx == 2:  # Tumor\n",
        "            tumor_y = cy + np.random.randint(-8, 8)\n",
        "            tumor_x = cx + np.random.randint(-8, 8)\n",
        "            tumor_mask = ((x_grid - tumor_x)**2 + (y_grid - tumor_y)**2) < 5**2\n",
        "            img[tumor_mask] += 0.6\n",
        "\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img_rgb = np.stack([img, img, img], axis=-1)\n",
        "        X.append(img_rgb)\n",
        "        y.append(class_idx)\n",
        "\n",
        "    return np.array(X, dtype=np.float32), np.array(y), class_names\n",
        "\n",
        "# 4. CNN 모델 정의\n",
        "def build_ct_cnn_model(input_shape=(64, 64, 3), num_classes=3):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 5. 데이터 준비 및 모델 훈련\n",
        "X_data, y_data, class_names = create_ct_dataset(600, (64, 64))\n",
        "y_cat = to_categorical(y_data, 3)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_data, y_cat, test_size=0.3, random_state=42, stratify=y_cat\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "model = build_ct_cnn_model()\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=16,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. 예측 함수\n",
        "def predict_ct_scan(model, image, class_names):\n",
        "    if len(image.shape) == 2:\n",
        "        image = np.stack([image, image, image], axis=-1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    predictions = model.predict(image, verbose=0)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class]\n",
        "\n",
        "    return class_names[predicted_class], confidence, predictions[0]\n",
        "\n",
        "# 7. 모델 저장\n",
        "model.save('ct_dicom_cnn_model.h5')\n",
        "\n",
        "# 8. 사용 예제\n",
        "# 저장된 모델 로딩\n",
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('ct_dicom_cnn_model.h5')\n",
        "\n",
        "# 실제 DICOM 파일로 예측\n",
        "# dicom_image = process_dicom_file('path/to/dicom/file.dcm')\n",
        "# if dicom_image is not None:\n",
        "#     result, confidence, probs = predict_ct_scan(loaded_model, dicom_image, class_names)\n",
        "#     print(f'예측: {result}, 확신도: {confidence:.4f}')\n",
        "\n",
        "print(\"모델 훈련 및 저장 완료!\")"
      ],
      "metadata": {
        "id": "wGLODxDs5knO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}